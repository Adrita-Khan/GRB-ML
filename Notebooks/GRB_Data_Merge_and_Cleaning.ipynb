{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- # Merge, clean, analyze, save dataset"
      ],
      "metadata": {
        "id": "aMKNiyARCsKZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LZJKayvCrra",
        "outputId": "6c90db55-6e20-44f6-ebb7-56e6ffd995fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 (CSV) shape: (127, 2)\n",
            "Dataset 1 columns: ['name', 'Redshift']\n",
            "\n",
            "Dataset 2 (CSV) shape: (4076, 306)\n",
            "Dataset 2 columns: ['name', 'ra', 'dec', 'trigger_time', 't90', 't90_error', 't90_start', 'fluence', 'fluence_error', 'flux_1024', 'flux_1024_error', 'flux_1024_time', 'flux_64', 'flux_64_error', 'flnc_band_ampl', 'flnc_band_ampl_pos_err', 'flnc_band_ampl_neg_err', 'flnc_band_epeak', 'flnc_band_epeak_pos_err', 'flnc_band_epeak_neg_err', 'flnc_band_alpha', 'flnc_band_alpha_pos_err', 'flnc_band_alpha_neg_err', 'flnc_band_beta', 'flnc_band_beta_pos_err', 'flnc_band_beta_neg_err', 'flnc_spectrum_start', 'flnc_spectrum_stop', 'pflx_best_fitting_model', 'pflx_best_model_redchisq', 'flnc_best_fitting_model', 'flnc_best_model_redchisq', 'actual_1024ms_interval', 'actual_256ms_interval', 'actual_64ms_interval', 'back_interval_high_start', 'back_interval_high_stop', 'back_interval_low_start', 'back_interval_low_stop', 'bcat_detector_mask', 'bcatalog', 'bii', 'duration_energy_high', 'duration_energy_low', 'error_radius', 'flnc_band_dof', 'flnc_band_ergflnc', 'flnc_band_ergflnc_error', 'flnc_band_ergflncb', 'flnc_band_ergflncb_error', 'flnc_band_ergflux', 'flnc_band_ergflux_error', 'flnc_band_phtflnc', 'flnc_band_phtflnc_error', 'flnc_band_phtflncb', 'flnc_band_phtflncb_error', 'flnc_band_phtflux', 'flnc_band_phtflux_error', 'flnc_band_phtfluxb', 'flnc_band_phtfluxb_error', 'flnc_band_redchisq', 'flnc_band_redfitstat', 'flnc_band_statistic', 'flnc_comp_ampl', 'flnc_comp_ampl_neg_err', 'flnc_comp_ampl_pos_err', 'flnc_comp_dof', 'flnc_comp_epeak', 'flnc_comp_epeak_neg_err', 'flnc_comp_epeak_pos_err', 'flnc_comp_ergflnc', 'flnc_comp_ergflnc_error', 'flnc_comp_ergflncb', 'flnc_comp_ergflncb_error', 'flnc_comp_ergflux', 'flnc_comp_ergflux_error', 'flnc_comp_index', 'flnc_comp_index_neg_err', 'flnc_comp_index_pos_err', 'flnc_comp_phtflnc', 'flnc_comp_phtflnc_error', 'flnc_comp_phtflncb', 'flnc_comp_phtflncb_error', 'flnc_comp_phtflux', 'flnc_comp_phtflux_error', 'flnc_comp_phtfluxb', 'flnc_comp_phtfluxb_error', 'flnc_comp_pivot', 'flnc_comp_pivot_neg_err', 'flnc_comp_pivot_pos_err', 'flnc_comp_redchisq', 'flnc_comp_redfitstat', 'flnc_comp_statistic', 'flnc_plaw_ampl', 'flnc_plaw_ampl_neg_err', 'flnc_plaw_ampl_pos_err', 'flnc_plaw_dof', 'flnc_plaw_ergflnc', 'flnc_plaw_ergflnc_error', 'flnc_plaw_ergflncb', 'flnc_plaw_ergflncb_error', 'flnc_plaw_ergflux', 'flnc_plaw_ergflux_error', 'flnc_plaw_index', 'flnc_plaw_index_neg_err', 'flnc_plaw_index_pos_err', 'flnc_plaw_phtflnc', 'flnc_plaw_phtflnc_error', 'flnc_plaw_phtflncb', 'flnc_plaw_phtflncb_error', 'flnc_plaw_phtflux', 'flnc_plaw_phtflux_error', 'flnc_plaw_phtfluxb', 'flnc_plaw_phtfluxb_error', 'flnc_plaw_pivot', 'flnc_plaw_pivot_neg_err', 'flnc_plaw_pivot_pos_err', 'flnc_plaw_redchisq', 'flnc_plaw_redfitstat', 'flnc_plaw_statistic', 'flnc_sbpl_ampl', 'flnc_sbpl_ampl_neg_err', 'flnc_sbpl_ampl_pos_err', 'flnc_sbpl_brken', 'flnc_sbpl_brken_neg_err', 'flnc_sbpl_brken_pos_err', 'flnc_sbpl_brksc', 'flnc_sbpl_brksc_neg_err', 'flnc_sbpl_brksc_pos_err', 'flnc_sbpl_dof', 'flnc_sbpl_ergflnc', 'flnc_sbpl_ergflnc_error', 'flnc_sbpl_ergflncb', 'flnc_sbpl_ergflncb_error', 'flnc_sbpl_ergflux', 'flnc_sbpl_ergflux_error', 'flnc_sbpl_indx1', 'flnc_sbpl_indx1_neg_err', 'flnc_sbpl_indx1_pos_err', 'flnc_sbpl_indx2', 'flnc_sbpl_indx2_neg_err', 'flnc_sbpl_indx2_pos_err', 'flnc_sbpl_phtflnc', 'flnc_sbpl_phtflnc_error', 'flnc_sbpl_phtflncb', 'flnc_sbpl_phtflncb_error', 'flnc_sbpl_phtflux', 'flnc_sbpl_phtflux_error', 'flnc_sbpl_phtfluxb', 'flnc_sbpl_phtfluxb_error', 'flnc_sbpl_pivot', 'flnc_sbpl_pivot_neg_err', 'flnc_sbpl_pivot_pos_err', 'flnc_sbpl_redchisq', 'flnc_sbpl_redfitstat', 'flnc_sbpl_statistic', 'flu_high', 'flu_low', 'fluence_batse', 'fluence_batse_error', 'flux_256', 'flux_256_error', 'flux_256_time', 'flux_64_time', 'flux_batse_1024', 'flux_batse_1024_error', 'flux_batse_1024_time', 'flux_batse_256', 'flux_batse_256_error', 'flux_batse_256_time', 'flux_batse_64', 'flux_batse_64_error', 'flux_batse_64_time', 'last_modified', 'lii', 'pflx_band_alpha', 'pflx_band_alpha_neg_err', 'pflx_band_alpha_pos_err', 'pflx_band_ampl', 'pflx_band_ampl_neg_err', 'pflx_band_ampl_pos_err', 'pflx_band_beta', 'pflx_band_beta_neg_err', 'pflx_band_beta_pos_err', 'pflx_band_dof', 'pflx_band_epeak', 'pflx_band_epeak_neg_err', 'pflx_band_epeak_pos_err', 'pflx_band_ergflnc', 'pflx_band_ergflnc_error', 'pflx_band_ergflncb', 'pflx_band_ergflncb_error', 'pflx_band_ergflux', 'pflx_band_ergflux_error', 'pflx_band_phtflnc', 'pflx_band_phtflnc_error', 'pflx_band_phtflncb', 'pflx_band_phtflncb_error', 'pflx_band_phtflux', 'pflx_band_phtflux_error', 'pflx_band_phtfluxb', 'pflx_band_phtfluxb_error', 'pflx_band_redchisq', 'pflx_band_redfitstat', 'pflx_band_statistic', 'pflx_comp_ampl', 'pflx_comp_ampl_neg_err', 'pflx_comp_ampl_pos_err', 'pflx_comp_dof', 'pflx_comp_epeak', 'pflx_comp_epeak_neg_err', 'pflx_comp_epeak_pos_err', 'pflx_comp_ergflnc', 'pflx_comp_ergflnc_error', 'pflx_comp_ergflncb', 'pflx_comp_ergflncb_error', 'pflx_comp_ergflux', 'pflx_comp_ergflux_error', 'pflx_comp_index', 'pflx_comp_index_neg_err', 'pflx_comp_index_pos_err', 'pflx_comp_phtflnc', 'pflx_comp_phtflnc_error', 'pflx_comp_phtflncb', 'pflx_comp_phtflncb_error', 'pflx_comp_phtflux', 'pflx_comp_phtflux_error', 'pflx_comp_phtfluxb', 'pflx_comp_phtfluxb_error', 'pflx_comp_pivot', 'pflx_comp_pivot_neg_err', 'pflx_comp_pivot_pos_err', 'pflx_comp_redchisq', 'pflx_comp_redfitstat', 'pflx_comp_statistic', 'pflx_plaw_ampl', 'pflx_plaw_ampl_neg_err', 'pflx_plaw_ampl_pos_err', 'pflx_plaw_dof', 'pflx_plaw_ergflnc', 'pflx_plaw_ergflnc_error', 'pflx_plaw_ergflncb', 'pflx_plaw_ergflncb_error', 'pflx_plaw_ergflux', 'pflx_plaw_ergflux_error', 'pflx_plaw_index', 'pflx_plaw_index_neg_err', 'pflx_plaw_index_pos_err', 'pflx_plaw_phtflnc', 'pflx_plaw_phtflnc_error', 'pflx_plaw_phtflncb', 'pflx_plaw_phtflncb_error', 'pflx_plaw_phtflux', 'pflx_plaw_phtflux_error', 'pflx_plaw_phtfluxb', 'pflx_plaw_phtfluxb_error', 'pflx_plaw_pivot', 'pflx_plaw_pivot_neg_err', 'pflx_plaw_pivot_pos_err', 'pflx_plaw_redchisq', 'pflx_plaw_redfitstat', 'pflx_plaw_statistic', 'pflx_sbpl_ampl', 'pflx_sbpl_ampl_neg_err', 'pflx_sbpl_ampl_pos_err', 'pflx_sbpl_brken', 'pflx_sbpl_brken_neg_err', 'pflx_sbpl_brken_pos_err', 'pflx_sbpl_brksc', 'pflx_sbpl_brksc_neg_err', 'pflx_sbpl_brksc_pos_err', 'pflx_sbpl_dof', 'pflx_sbpl_ergflnc', 'pflx_sbpl_ergflnc_error', 'pflx_sbpl_ergflncb', 'pflx_sbpl_ergflncb_error', 'pflx_sbpl_ergflux', 'pflx_sbpl_ergflux_error', 'pflx_sbpl_indx1', 'pflx_sbpl_indx1_neg_err', 'pflx_sbpl_indx1_pos_err', 'pflx_sbpl_indx2', 'pflx_sbpl_indx2_neg_err', 'pflx_sbpl_indx2_pos_err', 'pflx_sbpl_phtflnc', 'pflx_sbpl_phtflnc_error', 'pflx_sbpl_phtflncb', 'pflx_sbpl_phtflncb_error', 'pflx_sbpl_phtflux', 'pflx_sbpl_phtflux_error', 'pflx_sbpl_phtfluxb', 'pflx_sbpl_phtfluxb_error', 'pflx_sbpl_pivot', 'pflx_sbpl_pivot_neg_err', 'pflx_sbpl_pivot_pos_err', 'pflx_sbpl_redchisq', 'pflx_sbpl_redfitstat', 'pflx_sbpl_statistic', 'pflx_spectrum_start', 'pflx_spectrum_stop', 'scat_detector_mask', 'scatalog', 't50', 't50_error', 't50_start', 'trigger_name']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the datasets directly as CSVs\n",
        "df1 = pd.read_csv('https://raw.githubusercontent.com/Adrita-Khan/GRB-ML/main/Data/GBM_Known_Redshift.csv')\n",
        "df2 = pd.read_csv('https://raw.githubusercontent.com/Adrita-Khan/GRB-ML/main/Data/GBM_data_full.csv')\n",
        "\n",
        "# Display basic info about the datasets\n",
        "print(\"Dataset 1 (CSV) shape:\", df1.shape)\n",
        "print(\"Dataset 1 columns:\", df1.columns.tolist())\n",
        "print(\"\\nDataset 2 (CSV) shape:\", df2.shape)\n",
        "print(\"Dataset 2 columns:\", df2.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'name' column exists in both datasets\n",
        "if 'name' not in df1.columns:\n",
        "    print(\"\\nWarning: 'name' column not found in dataset 1\")\n",
        "    print(\"Available columns:\", df1.columns.tolist())\n",
        "\n",
        "if 'name' not in df2.columns:\n",
        "    print(\"\\nWarning: 'name' column not found in dataset 2\")\n",
        "    print(\"Available columns:\", df2.columns.tolist())"
      ],
      "metadata": {
        "id": "l3rdO02aDVFJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets on 'name' column (inner join to keep only common names)\n",
        "merged_df = pd.merge(df1, df2, on='name', how='inner', suffixes=('_df1', '_df2'))\n",
        "\n",
        "print(f\"\\nAfter merging on common 'name' values:\")\n",
        "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
        "\n",
        "# Remove rows with missing values\n",
        "cleaned_df = merged_df.dropna()\n",
        "\n",
        "print(f\"\\nAfter removing rows with missing values:\")\n",
        "print(f\"Cleaned dataset shape: {cleaned_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00AYFc2DkGw",
        "outputId": "750b523b-9ee6-4f14-f90b-173eb864266b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After merging on common 'name' values:\n",
            "Merged dataset shape: (127, 307)\n",
            "\n",
            "After removing rows with missing values:\n",
            "Cleaned dataset shape: (124, 307)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all columns with string (object) data types\n",
        "cleaned_df = cleaned_df.drop(columns=cleaned_df.select_dtypes(include=['object']).columns)\n",
        "\n",
        "print(f\"\\nAfter dropping string columns:\")\n",
        "print(f\"Final dataset shape: {cleaned_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXw8qrQsDo7A",
        "outputId": "2dde015c-0c3e-4dc0-dc4a-36c8aada8583"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After dropping string columns:\n",
            "Final dataset shape: (124, 293)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Remove duplicate columns ---\n",
        "# # Find duplicate column names\n",
        "# duplicates = cleaned_df.columns[cleaned_df.columns.duplicated()]\n",
        "# print(\"Duplicate column names:\", duplicates.tolist())\n",
        "\n",
        "# # Transpose the DataFrame and look for duplicated columns\n",
        "# duplicate_cols = cleaned_df.T.duplicated()\n",
        "\n",
        "# # Drop duplicated columns\n",
        "# cleaned_df = cleaned_df.loc[:, ~duplicate_cols]\n",
        "\n",
        "# # Print remaining columns\n",
        "# print(\"\\nAfter removing duplicate columns:\")\n",
        "# print(f\"Current number of columns: {cleaned_df.shape[1]}\")"
      ],
      "metadata": {
        "id": "YUYqDnbrD0lw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first few rows and summary info\n",
        "# print(f\"\\nFirst 5 rows of final dataset:\")\n",
        "# print(cleaned_df.head())\n",
        "\n",
        "# print(f\"\\nDataset info:\")\n",
        "# print(cleaned_df.info())\n",
        "\n",
        "# print(f\"\\nMissing values check:\")\n",
        "# print(cleaned_df.isnull().sum().sum())  # Should be 0"
      ],
      "metadata": {
        "id": "TLuIF42IDsFI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final cleaned dataset as a NumPy array\n",
        "cleaned_array = cleaned_df.to_numpy()\n",
        "\n",
        "# Optionally save it as a .npy file\n",
        "np.save('merged_cleaned_dataset.npy', cleaned_array)\n",
        "print(\"\\nFinal dataset saved as 'merged_cleaned_dataset.npy'\")\n",
        "\n",
        "# Save as CSV too\n",
        "cleaned_df.to_csv('merged_cleaned_dataset.csv', index=False)\n",
        "print(\"\\nFinal dataset saved as 'merged_cleaned_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-bo3ClkD--I",
        "outputId": "97c1004c-8f58-4d6d-ffc5-6c28a182e3bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final dataset saved as 'merged_cleaned_dataset.npy'\n",
            "\n",
            "Final dataset saved as 'merged_cleaned_dataset.csv'\n"
          ]
        }
      ]
    }
  ]
}